# SONVÃ‰ ğŸ¤âœ¨

[![Python](https://img.shields.io/badge/Python-3.9%2B-blue)](https://www.python.org/)
[![Next.js](https://img.shields.io/badge/Next.js-12-blue)](https://nextjs.org/)

> **SONVÃ‰** transforms your voice into wearable art. By analyzing your speech with advanced signal processing and machine learning, SONVÃ‰ creates unique accessory designs that reflect your emotions. Every design is as unique as your mood!

## ğŸš€ Features

- ğŸ™ **Voice-Activated Design** â€“ Converts speech into dynamic accessory patterns.
- ğŸ¤– **Emotion Detection** â€“ Utilizes a CNN-LSTM model to classify your emotions from audio.
- ğŸ”Š **Signal Processing** â€“ Extracts dominant frequencies (via DTFT) and MFCC features from your voice.
- ğŸ¨ **Design Mapping** â€“ Maps detected emotions to design elements (like color and pattern).
- ğŸ’¡ **Cost-Effective & Scalable** â€“ Built on free-tier cloud services for effortless deployment.

## ğŸ› ï¸ Tech Stack

- **Backend:** Python, FastAPI, TensorFlow/Keras, Librosa, Uvicorn
- **Frontend:** Next.js, React, Three.js (for visualizations)
- **Database:** PostgreSQL (via Supabase) or SQLite
- **Storage:** Cloudinary
- **Deployment:** Docker, Vercel, Render/Fly.io/Cloud Run

## ğŸ“¥ Installation

### 1ï¸âƒ£ Clone the Repository

```sh
git clone https://github.com/your-username/SONVE.git
cd SONVE
```

````

### 2ï¸âƒ£ Backend Setup

- **Navigate to the backend directory:**

  ```sh
  cd backend
  ```

- **Create & activate a virtual environment:**

  ```sh
  python3 -m venv venv
  source venv/bin/activate  # On Windows: venv\Scripts\activate
  ```

- **Install dependencies:**

  ```sh
  pip install -r requirements.txt
  ```

- **Configure Environment Variables:**
  Create a `.env` file in the `backend` directory:

  ```ini
  API_HOST=0.0.0.0
  API_PORT=8000
  DATABASE_URL=<your_database_url>
  CLOUDINARY_CLOUD_NAME=<your_cloudinary_cloud_name>
  CLOUDINARY_API_KEY=<your_cloudinary_api_key>
  CLOUDINARY_API_SECRET=<your_cloudinary_api_secret>
  MODEL_PATH=./model.h5
  ```

- **Start the FastAPI Server:**

  ```sh
  uvicorn api.main:app --reload
  ```

### 3ï¸âƒ£ Frontend Setup

- **Navigate to the frontend directory:**

  ```sh
  cd ../frontend
  ```

- **Install Node dependencies:**

  ```sh
  npm install
  ```

- **Create a `.env.local` file:**

  ```ini
  NEXT_PUBLIC_API_URL=http://localhost:8000
  ```

- **Start the Next.js Development Server:**

  ```sh
  npm run dev
  ```

- Open your browser at [http://localhost:3000](http://localhost:3000) to see the app.

## ğŸ“‚ Project Structure

```plaintext
SONVE/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ audio_processing/
â”‚   â”‚   â”œâ”€â”€ record_audio.py       # Record or import audio
â”‚   â”‚   â”œâ”€â”€ preprocess.py         # Noise reduction & normalization
â”‚   â”‚   â””â”€â”€ feature_extraction.py # MFCC & DTFT extraction functions
â”‚   â”œâ”€â”€ ml_model/
â”‚   â”‚   â”œâ”€â”€ train_model.py        # CNN-LSTM model training script
â”‚   â”‚   â””â”€â”€ predict_emotion.py    # Emotion prediction logic
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ main.py               # FastAPI application entry point
â”‚   â”‚   â””â”€â”€ routes/
â”‚   â”‚       â”œâ”€â”€ audio.py          # Audio processing endpoints
â”‚   â”‚       â””â”€â”€ health.py         # Health check endpoint
â”‚   â”œâ”€â”€ database/
â”‚   â”‚   â”œâ”€â”€ models.py             # Database schema models
â”‚   â”‚   â””â”€â”€ crud.py               # CRUD operations
â”‚   â”œâ”€â”€ requirements.txt          # Python dependencies
â”‚   â””â”€â”€ Dockerfile                # Docker configuration for backend
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ app/                      # Next.js App Directory
â”‚   â”‚   â”œâ”€â”€ layout.js             # Global layout component
â”‚   â”‚   â””â”€â”€ page.js               # Main page with audio upload & preview UI
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â””â”€â”€ TwoDPattern.js        # 2D pattern visualization component
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â””â”€â”€ api.js                # API communication layer
â”‚   â”œâ”€â”€ next.config.js            # Next.js configuration
â”‚   â”œâ”€â”€ package.json              # Node dependencies
â”‚   â””â”€â”€ Dockerfile                # Docker configuration for frontend
â””â”€â”€ deployment/
    â”œâ”€â”€ backend-deployment.yaml   # Kubernetes deployment for backend
    â”œâ”€â”€ frontend-deployment.yaml  # Kubernetes deployment for frontend
    â””â”€â”€ ingress.yaml              # Ingress configuration for routing
```

## âš™ï¸ Usage

- **Local Development:**
  Use the UI to record or upload audio. The backend processes your voice, classifies your emotion, and generates a 2D design pattern that reflects your mood.

- **API Testing:**
  Visit [http://localhost:8000/docs](http://localhost:8000/docs) for interactive API documentation.

## ğŸš§ Roadmap

- [x] **Project Setup & Environment Configuration**
- [ ] **Audio Processing & Feature Extraction**
- [ ] **ML Model Development & Training**
- [ ] **Backend API Integration**
- [ ] **Frontend UI Development**
- [ ] **End-to-End Integration & Testing**
- [ ] **Deployment to Production**
- [ ] **Performance Optimization & Scaling**

_Transform your voice into art with SONVÃ‰!_
````
